# Crear los archivos 'index.html', 'styles.css' y 'script.js' con el contenido proporcionado

# Contenido de index.html
index_html_content = """
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Proyecto de Procesamiento de Lenguaje Natural</title>
    <link rel="stylesheet" href="styles.css">
    <script src="script.js" defer></script>
</head>
<body>
    <header>
        <h1>Proyecto de Procesamiento de Lenguaje Natural</h1>
        <p>Una exploración completa del análisis de texto con técnicas avanzadas</p>
    </header>

    <nav>
        <ul>
            <li><a href="#descripcion">Descripción</a></li>
            <li><a href="#preprocesamiento">Preprocesamiento</a></li>
            <li><a href="#modelos">Modelos</a></li>
            <li><a href="#visualizacion">Visualización</a></li>
            <li><a href="#codigo">Código</a></li>
        </ul>
    </nav>

    <section id="descripcion">
        <h2>Descripción del Proyecto</h2>
        <p>Este proyecto se enfoca en el análisis de transcripciones de charlas TED en español usando técnicas de procesamiento de lenguaje natural (NLP). 

### Descripción del Proyecto:
1. **Preprocesamiento:** Limpieza de texto con NLTK, eliminando caracteres especiales, "stopwords" y aplicando lematización.
2. **Vectorización:** Transformación del texto en datos numéricos mediante TF-IDF para capturar la importancia de las palabras en los documentos.
3. **Balanceo de Clases:** Uso de SMOTE para equilibrar las clases en el conjunto de datos, mejorando la calidad de los modelos.
4. **Modelado:** Entrenamiento de varios modelos de clasificación (Random Forest, SVM, Naive Bayes) para categorizar las charlas.
5. **Evaluación y Visualización:** Análisis de los resultados de los modelos y agrupamiento de datos con K-Means.

El proyecto culmina en una página web dinámica que presenta el proceso y los resultados obtenidos.</p>
    </section>

    <section id="preprocesamiento">
        <h2>Preprocesamiento de Texto</h2>
        <p>El procesamiento de este proyecto se centra en transformar y preparar las transcripciones de charlas TED para su análisis y clasificación. 

### Descripción del Procesamiento:
1. **Limpieza de Texto:** Se utiliza NLTK para eliminar caracteres especiales, URLs, menciones y "stopwords". El texto se convierte a minúsculas y se lematiza para reducir las palabras a su forma base.
2. **Vectorización:** Se aplica TF-IDF para convertir el texto en una representación numérica, destacando la relevancia de palabras y frases (unigramas y bigramas) en los documentos.
3. **Balanceo de Clases:** Para abordar el desbalanceo en las categorías, se utiliza SMOTE, creando muestras sintéticas que equilibran el conjunto de datos.
4. **División de Datos:** Los datos se dividen en conjuntos de entrenamiento y prueba para evaluar el rendimiento de los modelos.
5. **Modelado:** Entrenamiento de diferentes modelos de clasificación (Random Forest, SVM, Naive Bayes) con los datos procesados.
6. **Evaluación:** Los resultados se analizan mediante métricas como la precisión y la puntuación de silueta para el agrupamiento de datos.

Este procesamiento garantiza que los modelos trabajen con datos limpios, balanceados y optimizados para una clasificación efectiva.</p>
        <pre><code>
# Función de preprocesamiento mejorada
def preprocesar_texto(texto):
    # Convertir a minúsculas
    texto = texto.lower()
    # Eliminar URL, menciones y caracteres especiales
    texto = re.sub(r"http\\S+|www\\S+|https\\S+", '', texto)
    ...
        </code></pre>
    </section>

    <section id="modelos">
        <h2>Modelos de Clasificación</h2>
        <p>En este proyecto, se implementan y evalúan tres modelos de clasificación para categorizar las transcripciones de charlas TED en español:

### Descripción de los Modelos:
1. **Random Forest:** 
   - Es un modelo basado en la construcción de múltiples árboles de decisión, creando un "bosque" que vota por la categoría final. 
   - Este modelo es robusto y maneja bien conjuntos de datos con muchas características.
   - En el proyecto, se utiliza con 200 árboles y una profundidad máxima definida para evitar sobreajuste.

2. **SVM (Support Vector Machine):**
   - Busca encontrar un hiperplano óptimo que separe las clases en el espacio de características.
   - En este caso, se utiliza un kernel lineal para clasificar las transcripciones.
   - SVM es efectivo en problemas con muchas características, como es común en análisis de texto.

3. **Naive Bayes (MultinomialNB):**
   - Un modelo probabilístico que asume independencia entre las características.
   - Se adapta bien al procesamiento de lenguaje natural, especialmente en tareas de clasificación de texto.
   - En este proyecto, se utiliza la versión multinomial, que es adecuada para datos representados por frecuencias, como el TF-IDF.

### Evaluación:
- Los modelos se entrenan y evalúan usando métricas como precisión y un informe de clasificación para medir el rendimiento en la predicción de categorías.
  
Cada modelo tiene sus ventajas, y la diversidad en los enfoques permite comparar y seleccionar el mejor rendimiento para la tarea de clasificación.</p>
        <ul>
            <li><strong>Random Forest:</strong> Precisión: 85%</li>
            <li><strong>SVM:</strong> Precisión: 83%</li>
            <li><strong>Naive Bayes:</strong> Precisión: 78%</li>
        </ul>
    </section>

    <section id="visualizacion">
        <h2>Visualización de Datos</h2>
        <p>En este proyecto, la visualización se utiliza para explorar y comprender mejor la estructura de los datos y los resultados del análisis.

### Descripción de la Visualización:

1. **Reducción de Dimensionalidad con PCA:** 
   - Se aplica Análisis de Componentes Principales (PCA) para reducir la alta dimensionalidad de los datos generados por la vectorización TF-IDF.
   - PCA comprime los datos a 50 componentes principales, conservando la mayor parte de la variabilidad. Esto facilita la visualización y el análisis del agrupamiento en un espacio más manejable.

2. **Agrupamiento con K-Means:**
   - Tras la reducción de dimensionalidad, se aplica el algoritmo de K-Means para agrupar los datos en 5 clusters.
   - Se evalúa la calidad de los clusters usando la puntuación de silueta, que mide qué tan bien se separan los grupos, ayudando a identificar patrones y similitudes entre las transcripciones.

3. **Gráficos Interactivos:** 
   - En la página web dinámica, se pueden incluir gráficos interactivos para mostrar los resultados y el agrupamiento de los datos. Aunque no se detallan los gráficos específicos en el código, se menciona la posibilidad de utilizar bibliotecas como Plotly para representar de forma visual los resultados de los modelos y el agrupamiento.

Estas visualizaciones permiten analizar la distribución de los datos, identificar patrones y evaluar la eficacia de los modelos utilizados en la clasificación.</p>
        <div id="grafico"></div>
    </section>

    <section id="codigo">
        <h2>Código del Proyecto</h2>
        <p>Puedes encontrar todo el código de este proyecto en nuestro <a href="https://github.com/galotravez/galotravez/blob/main/00_TRABAJO_FINAL_NLP.ipynb">repositorio de GitHub</a>.</p>
    </section>

    <footer>
        <p>&copy; 2024 Proyecto NLP - Desarrollado por [Tu Nombre]</p>
    </footer>
</body>
</html>
"""

# Contenido de styles.css
styles_css_content = """
/* Estilos básicos */
body {
    font-family: Arial, sans-serif;
    line-height: 1.6;
    background: #f4f4f4;
    color: #333;
    margin: 0;
}

/* Encabezado */
header {
    background: #333;
    color: #fff;
    padding: 20px;
    text-align: center;
}

/* Barra de navegación */
nav {
    background: #444;
    padding: 10px;
}

nav ul {
    list-style: none;
    padding: 0;
    display: flex;
    justify-content: center;
}

nav ul li {
    margin: 0 15px;
}

nav ul li a {
    color: white;
    text-decoration: none;
}

/* Secciones */
section {
    padding: 20px;
    margin: 20px auto;
    max-width: 800px;
    background: #fff;
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
}

/* Código */
pre {
    background: #f4f4f4;
    padding: 10px;
    overflow-x: auto;
}

/* Footer */
footer {
    text-align: center;
    padding: 20px;
    background: #333;
    color: #fff;
    position: fixed;
    bottom: 0;
    width: 100%;
}
"""

# Contenido de script.js
script_js_content = """
document.addEventListener('DOMContentLoaded', function() {
    // Ejemplo: Crear un gráfico básico con JavaScript (puedes reemplazar con Plotly u otra biblioteca)
    var graficoDiv = document.getElementById('grafico');
    graficoDiv.innerHTML = '<p>Aquí irá un gráfico interactivo.</p>';

    // Aquí puedes añadir más lógica para gráficos interactivos o animaciones
});
"""

# Guardar los contenidos en archivos
with open('/mnt/data/index.html', 'w') as file:
    file.write(index_html_content)

with open('/mnt/data/styles.css', 'w') as file:
    file.write(styles_css_content)

with open('/mnt/data/script.js', 'w') as file:
    file.write(script_js_content)

# Crear un archivo zip con todos los archivos
import zipfile

zip_path = '/mnt/data/proyecto_nlp_web.zip'
with zipfile.ZipFile(zip_path, 'w') as zip_file:
    zip_file.write('/mnt/data/index.html', 'index.html')
    zip_file.write('/mnt/data/styles.css', 'styles.css')
    zip_file.write('/mnt/data/script.js', 'script.js')

# Proveer el archivo zip listo para descargar
zip_path
